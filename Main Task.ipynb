{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3a28c76-869c-4482-a1ee-72ada7960e3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Main Task\n",
    "\n",
    "You have meen selected as the Lead Data Engineer for a project involving Airbnb Data.\n",
    "\n",
    "The customer has published some data on Kaggle and he is looking forward getting some insights from it. He is a business person which is looking forward exploring new areas in order to improve the profit of his platform.\n",
    "\n",
    "Your task will be gathering the data from the platform, making sure that the data is relevant and clean and then saving it for further use. You will need to follow the **Medalion Architecture** Principle for organizing the data within the catalog. \n",
    "\n",
    "A previous team has started working on this initiative, but they got stuck on the way and they will need your help. Within this DBC Archive you will find the **Setup Notebook** containing the connection to Kaggle as well as a short baseline structure on how the Data should be processed. You will also find a folder containing some notebooks where the team has performed some research on the data, but they didn't managed to link it together in one piece.\n",
    "\n",
    "Your task will be establishing a **Medalion Architecture** Catalog representing the data provided by the customer. Further on, you will need to use the **Gold Layer** to perform **Analysis** on the Data as well as running **Predictions** that could help the customer understand better different trends that could be found out from the Data.\n",
    "\n",
    "Remember that the customer is not a technical person, so all the results of your work should be in a format that could be understood by a Business Person (Graphs, Histograms, Diagrams, Trends etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92269393-1373-499c-8bc3-26bc59a9a7c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Technical consideration for the Data Catalog\n",
    "\n",
    "The previous team has started working on the solution by creating some baseline tables within the Data Catalog. However, their existing naming convention can be misleading.\n",
    "\n",
    "For the Data Catalog, the Data Architect recommended the following naming convention for the tables:\n",
    "\n",
    "**\\<medalion-layer-name>_\\<table_name>_tbl**\n",
    "\n",
    "If you already have the tables generated by the previous team, feel free to delete them after you have established the **Medalion Architecture** in the desired format.\n",
    "\n",
    "You can even modify the naming convention from the Setup itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "101e59d9-c9cf-45d2-896e-6a9001af1fdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Technical Considerations for Code Structure\n",
    "\n",
    "Your Code should be organised in a Clean and logic way. We recommend spliting the logic of the Data Processing Pipeline as much as possible in order to tackle atomic principles in Separate Notebooks. A long notebook containing all the code could be fine as well, but sometimes it can be hard to integrate as part of a Larger Data Pipeline later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d5a09fe-8a7e-4799-87b5-d4c713a878ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Other Technical Considerations\n",
    "\n",
    "Please be advised that the previous team might have not followed the Considerations above. You might need to change some table namings from time to time, as they might have been named differently.\n",
    "\n",
    "Feel free to explore further for performing this task. The team came up with some example notebooks for performing this task, but that does not mean that this is the only option.\n",
    "\n",
    "We recommend writing the code in Spark as much as possible because of the fact that the customer expects this data to grow significantly in the future, as he is planning to add data for multiple other cities. An approach using Pandas will be acceptable as well, but the recommendation and the best practices received still points out to using Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64b99e94-0af0-407f-8cf7-257c2f53b3dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Additional Resources\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/rusiano/madrid-airbnb-data\n",
    "\n",
    "hint: Explore the **Data Card**, **Code**, **Discussion** and **Suggestions** tabs, as they could provide valuable insights for your work.\n",
    "\n",
    "In case you will need further clarifications for this task, you can reach the Architect on the communication platform used earlier."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Main Task",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
